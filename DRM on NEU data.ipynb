{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from os import listdir\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "groups = [\"Cr\",\"In\",\"Pa\",\"PS\",\"RS\",\"Sc\"]\n",
    "data = [[] for i in range(len(groups))]\n",
    "\n",
    "for f in listdir(\"data\"):\n",
    "    image = np.reshape(cv2.equalizeHist(cv2.imread(\"data/\"+f,0)),[40000])\n",
    "    data[groups.index(f[0:2])].append(image)\n",
    "    \n",
    "\n",
    "from pylearn2.models.model import Model\n",
    "from pylearn2.space import VectorSpace\n",
    "from pylearn2.models.mlp import PretrainedLayer\n",
    "import theano\n",
    "from theano import tensor\n",
    "from pylearn2.utils import sharedX\n",
    "import theano.tensor as T\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "__author__ = \"Li Yao\"\n",
    "\"\"\"\n",
    "See readme.txt\n",
    "\n",
    "A small example of how to glue shining features of pylearn2 together\n",
    "to train models layer by layer.\n",
    "\"\"\"\n",
    "\n",
    "MAX_EPOCHS_UNSUPERVISED = 1\n",
    "MAX_EPOCHS_SUPERVISED = 2\n",
    "\n",
    "from pylearn2.config import yaml_parse\n",
    "from pylearn2.corruption import BinomialCorruptor\n",
    "from pylearn2.corruption import GaussianCorruptor\n",
    "from pylearn2.costs.mlp import Default\n",
    "from pylearn2.models.autoencoder import Autoencoder, DenoisingAutoencoder\n",
    "from pylearn2.models.rbm import GaussianBinaryRBM\n",
    "from pylearn2.models.DRM import DeepEncoder\n",
    "from pylearn2.models.softmax_regression import SoftmaxRegression\n",
    "from pylearn2.training_algorithms.sgd import SGD\n",
    "from pylearn2.training_algorithms.sgd import AnnealedLearningRate\n",
    "from pylearn2.training_algorithms.sgd import OneOverEpoch\n",
    "from pylearn2.costs.autoencoder import MeanSquaredReconstructionError\n",
    "from pylearn2.termination_criteria import EpochCounter\n",
    "from pylearn2.datasets.dense_design_matrix import DenseDesignMatrix\n",
    "from pylearn2.energy_functions.rbm_energy import GRBM_Type_1\n",
    "from pylearn2.blocks import StackedBlocks\n",
    "from pylearn2.datasets.transformer_dataset import TransformerDataset\n",
    "from pylearn2.costs.ebm_estimation import SMD\n",
    "from pylearn2.costs.DRM import DRMCost\n",
    "from pylearn2.training_algorithms.sgd import MonitorBasedLRAdjuster\n",
    "from pylearn2.train import Train\n",
    "from optparse import OptionParser\n",
    "from pylearn2.datasets.honda import load_data\n",
    "import numpy\n",
    "import copy\n",
    "MAX_EPOCHS_UNSUPERVISED = 1\n",
    "MAX_EPOCHS_SUPERVISED = 2\n",
    "\n",
    "\n",
    "\n",
    "def get_autoencoder(structure):\n",
    "    n_input, n_output = structure\n",
    "    config = {\n",
    "        'nhid': n_output,\n",
    "        'nvis': n_input,\n",
    "        'tied_weights': True,\n",
    "        'act_enc': 'sigmoid',\n",
    "        'act_dec': 'sigmoid',\n",
    "        'irange': 0.001,\n",
    "    }\n",
    "    return Autoencoder(**config)\n",
    "\n",
    "def get_denoising_autoencoder(structure):\n",
    "    n_input, n_output = structure\n",
    "    curruptor = BinomialCorruptor(corruption_level=0.5)\n",
    "    config = {\n",
    "        'corruptor': curruptor,\n",
    "        'nhid': n_output,\n",
    "        'nvis': n_input,\n",
    "        'tied_weights': True,\n",
    "        'act_enc': 'sigmoid',\n",
    "        'act_dec': 'sigmoid',\n",
    "        'irange': 0.001,\n",
    "    }\n",
    "    return DenoisingAutoencoder(**config)\n",
    "\n",
    "def get_grbm(structure):\n",
    "    n_input, n_output = structure\n",
    "    config = {\n",
    "        'nvis': n_input,\n",
    "        'nhid': n_output,\n",
    "        \"irange\" : 0.05,\n",
    "        \"energy_function_class\" : GRBM_Type_1,\n",
    "        \"learn_sigma\" : True,\n",
    "        \"init_sigma\" : .4,\n",
    "        \"init_bias_hid\" : -2.,\n",
    "        \"mean_vis\" : False,\n",
    "        \"sigma_lr_scale\" : 1e-3\n",
    "        }\n",
    "\n",
    "    return GaussianBinaryRBM(**config)\n",
    "\n",
    "def get_logistic_regressor(structure):\n",
    "    n_input, n_output = structure\n",
    "\n",
    "    layer = SoftmaxRegression(n_classes=n_output, irange=0.02, nvis=n_input)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def get_layer_trainer_logistic(layer, trainset):\n",
    "    # configs on sgd\n",
    "\n",
    "    config = {'learning_rate': 0.1,\n",
    "              'cost' : Default(),\n",
    "              'batch_size': 10,\n",
    "              'monitoring_batches': 10,\n",
    "              'monitoring_dataset': trainset,\n",
    "              'termination_criterion': EpochCounter(max_epochs=50),\n",
    "              'update_callbacks': None\n",
    "              }\n",
    "\n",
    "    train_algo = SGD(**config)\n",
    "    model = layer\n",
    "    return Train(model = model,\n",
    "            dataset = trainset,\n",
    "            algorithm = train_algo,\n",
    "            extensions = None)\n",
    "\n",
    "def get_layer_trainer_sgd_autoencoder(layer, trainset):\n",
    "    # configs on sgd\n",
    "    train_algo = SGD(\n",
    "            learning_rate = 2*1e-3,\n",
    "              cost =  DRMCost(),\n",
    "              batch_size =  1,\n",
    "              monitoring_batches = 5,\n",
    "              monitoring_dataset =  trainset,\n",
    "              termination_criterion = EpochCounter(max_epochs=5),\n",
    "              update_callbacks =  None\n",
    "              )\n",
    "\n",
    "    model = layer\n",
    "    extensions = None\n",
    "    return Train(model = model,\n",
    "            algorithm = train_algo,\n",
    "            extensions = extensions,\n",
    "            save_path='my_model.pkl'\n",
    "            ,save_freq=1,\n",
    "            dataset = trainset)\n",
    "\n",
    "def get_layer_trainer_sgd_rbm(layer, trainset,epochs):\n",
    "    train_algo = SGD(\n",
    "        learning_rate = 1e-3,\n",
    "        batch_size =  1,\n",
    "        #\"batches_per_iter\" : 2000,\n",
    "        monitoring_batches =  5,\n",
    "        monitoring_dataset =  trainset,\n",
    "        cost = SMD(corruptor=GaussianCorruptor(stdev=0.4)),\n",
    "        termination_criterion =  EpochCounter(max_epochs=epochs),\n",
    "        )\n",
    "    model = layer\n",
    "    extensions = [MonitorBasedLRAdjuster()]\n",
    "    return Train(model = model, algorithm = train_algo,\n",
    "                 save_path='grbm.pkl',save_freq=1,\n",
    "                 extensions = extensions, dataset = trainset)\n",
    "\n",
    "\n",
    "\n",
    "def encoder_model(trainset):\n",
    "    design_matrix = trainset.get_design_matrix()\n",
    "    n_input = design_matrix.shape[1]\n",
    "    layers = []\n",
    "    structure = [[n_input, 500],[500, n_input]]\n",
    "    # layer 0: gaussianRBM\n",
    "    layers.append(get_grbm(structure[0]))\n",
    "    #layers.append(get_grbm(structure[1]))\n",
    "    #layers.append(get_grbm(structure[2]))\n",
    "    \n",
    "    #layers.append(get_grbm(structure[2]))\n",
    "    # layer 3: logistic regression used in supervised training                                                                                                                                               \n",
    "#    layers.append(get_logistic_regressor(structure[1]))\n",
    "    \n",
    "    trainset = [ trainset #,\n",
    "                #TransformerDataset( raw = trainset, transformer = layers[0] ),\n",
    "                #TransformerDataset( raw = trainset, transformer = StackedBlocks( layers[0:2] )),\n",
    "               ]\n",
    "\n",
    "    # construct layer trainers\n",
    "    layer_trainers = []\n",
    "    layer_trainers.append(get_layer_trainer_sgd_rbm(layers[0], trainset[0],5))\n",
    "    #layer_trainers.append(get_layer_trainer_sgd_rbm(layers[1], trainset[1],20))\n",
    "    #layer_trainers.append(get_layer_trainer_sgd_rbm(layers[2], trainset[2],20))\n",
    "\n",
    "    #layer_trainers.append(get_layer_trainer_sgd_rbm(layers[1], trainset[1],5))\n",
    "    #layer_trainers.append(get_layer_trainer_sgd_rbm(layers[2], trainset[2],5))\n",
    "    #layer_trainers.append(get_layer_trainer_logistic(layers[1], trainset[1]))\n",
    "    # unsupervised pretraining\n",
    "    for i, layer_trainer in enumerate(layer_trainers):\n",
    "        print('-----------------------------------')\n",
    "        print(' Unsupervised training layer %d, %s'%(i, layers[i].__class__))\n",
    "        print('-----------------------------------')\n",
    "        layer_trainer.main_loop()\n",
    "    encoder = DeepEncoder(layers)\n",
    "    print('\\n')\n",
    "    print('------------------------------------------------------')\n",
    "    print(' Unsupervised training done! Start Fine-tuing training...')\n",
    "    print('------------------------------------------------------')\n",
    "    print('\\n')\n",
    "    # supervised training\n",
    "    #layer_trainers[-1].main_loop()\n",
    "    trainer = get_layer_trainer_sgd_autoencoder(encoder,trainset[0])\n",
    "    trainer.main_loop()\n",
    "    return encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      " Unsupervised training layer 0, <class 'pylearn2.models.rbm.GaussianBinaryRBM'>\n",
      "-----------------------------------\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.0010000000475\n",
      "\tbias_vis: 0.0010000000475\n",
      "\tbias_hid: 0.0010000000475\n",
      "\tsigma_driver: 0.0010000000475\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 6.127932 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.030340 seconds\n",
      "Monitored channels: \n",
      "\tbias_hid_max\n",
      "\tbias_hid_mean\n",
      "\tbias_hid_min\n",
      "\tbias_vis_max\n",
      "\tbias_vis_mean\n",
      "\tbias_vis_min\n",
      "\th_max\n",
      "\th_mean\n",
      "\th_min\n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\treconstruction_error\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 91\n",
      "Compiling accum done. Time elapsed: 0.612159 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0\n",
      "\tbias_vis_max: 0.0\n",
      "\tbias_vis_mean: 0.0\n",
      "\tbias_vis_min: 0.0\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.464524328709\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 8.589e+05\n",
      "\treconstruction_error: 8.795e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 4.897342 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tbias_hid_max: -1.99999463558\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000038147\n",
      "\tbias_vis_max: 0.0118573233485\n",
      "\tbias_vis_mean: 0.0100658591837\n",
      "\tbias_vis_min: 0.00793431699276\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.898627400398\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 1.114e+05\n",
      "\treconstruction_error: 8.378e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 4.89734220505\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.271736 seconds\n",
      "Time this epoch: 4.904083 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tbias_hid_max: -1.99999463558\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000038147\n",
      "\tbias_vis_max: 0.0163549669087\n",
      "\tbias_vis_mean: 0.0139809483662\n",
      "\tbias_vis_min: 0.0108503596857\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.906706690788\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 7.068e+04\n",
      "\treconstruction_error: 8.202e+08\n",
      "\ttotal_seconds_last_epoch: 8.44012069702\n",
      "\ttraining_seconds_this_epoch: 4.90408277512\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 4.128957 seconds\n",
      "Time this epoch: 4.931683 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tbias_hid_max: -1.99999463558\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000038147\n",
      "\tbias_vis_max: 0.0195454321802\n",
      "\tbias_vis_mean: 0.0167474374175\n",
      "\tbias_vis_min: 0.0129119083285\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.9100933671\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 5.387e+04\n",
      "\treconstruction_error: 8.079e+08\n",
      "\ttotal_seconds_last_epoch: 9.30628967285\n",
      "\ttraining_seconds_this_epoch: 4.93168306351\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.227719 seconds\n",
      "Time this epoch: 4.992994 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tbias_hid_max: -1.99999463558\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000038147\n",
      "\tbias_vis_max: 0.0220917444676\n",
      "\tbias_vis_mean: 0.0189538560808\n",
      "\tbias_vis_min: 0.0145536288619\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.91148006916\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 4.434e+04\n",
      "\treconstruction_error: 7.981e+08\n",
      "\ttotal_seconds_last_epoch: 8.43521881104\n",
      "\ttraining_seconds_this_epoch: 4.99299430847\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.455391 seconds\n",
      "Time this epoch: 4.853829 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tbias_hid_max: -1.99999463558\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000038147\n",
      "\tbias_vis_max: 0.0242390502244\n",
      "\tbias_vis_mean: 0.0208176150918\n",
      "\tbias_vis_min: 0.0159425660968\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.912000000477\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 3.808e+04\n",
      "\treconstruction_error: 7.898e+08\n",
      "\ttotal_seconds_last_epoch: 8.73635292053\n",
      "\ttraining_seconds_this_epoch: 4.85382890701\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.313554 seconds\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.848808 seconds\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      " Unsupervised training done! Start Fine-tuing training...\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.00200000009499\n",
      "\tbias_vis: 0.00200000009499\n",
      "\tbias_hid: 0.00200000009499\n",
      "\tsigma_driver: 0.00200000009499\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.564304 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.012914 seconds\n",
      "Monitored channels: \n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 29\n",
      "Compiling accum done. Time elapsed: 0.165637 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.696e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 6.471005 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.696e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 6.47100496292\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.133304 seconds\n",
      "Time this epoch: 6.368456 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.696e+08\n",
      "\ttotal_seconds_last_epoch: 9.74829673767\n",
      "\ttraining_seconds_this_epoch: 6.36845588684\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.196474 seconds\n",
      "Time this epoch: 6.313083 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.696e+08\n",
      "\ttotal_seconds_last_epoch: 9.70560455322\n",
      "\ttraining_seconds_this_epoch: 6.31308364868\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.081802 seconds\n",
      "Time this epoch: 6.374063 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.696e+08\n",
      "\ttotal_seconds_last_epoch: 9.52951717377\n",
      "\ttraining_seconds_this_epoch: 6.37406301498\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.182827 seconds\n",
      "Time this epoch: 6.277704 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.696e+08\n",
      "\ttotal_seconds_last_epoch: 9.70087909698\n",
      "\ttraining_seconds_this_epoch: 6.27770423889\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.096436 seconds\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.466208 seconds\n",
      "-----------------------------------\n",
      " Unsupervised training layer 0, <class 'pylearn2.models.rbm.GaussianBinaryRBM'>\n",
      "-----------------------------------\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.0010000000475\n",
      "\tbias_vis: 0.0010000000475\n",
      "\tbias_hid: 0.0010000000475\n",
      "\tsigma_driver: 0.0010000000475\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.616931 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.026402 seconds\n",
      "Monitored channels: \n",
      "\tbias_hid_max\n",
      "\tbias_hid_mean\n",
      "\tbias_hid_min\n",
      "\tbias_vis_max\n",
      "\tbias_vis_mean\n",
      "\tbias_vis_min\n",
      "\th_max\n",
      "\th_mean\n",
      "\th_min\n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\treconstruction_error\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 91\n",
      "Compiling accum done. Time elapsed: 0.789343 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0\n",
      "\tbias_vis_max: 0.0\n",
      "\tbias_vis_mean: 0.0\n",
      "\tbias_vis_min: 0.0\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.463120996952\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 8.776e+05\n",
      "\treconstruction_error: 8.987e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 4.956580 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tbias_hid_max: -1.99999976158\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000309944\n",
      "\tbias_vis_max: 0.0128593882546\n",
      "\tbias_vis_mean: 0.0101107098162\n",
      "\tbias_vis_min: 0.0064265858382\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.866186618805\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 1.123e+05\n",
      "\treconstruction_error: 8.567e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 4.95658016205\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.264373 seconds\n",
      "Time this epoch: 4.825050 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tbias_hid_max: -1.99999976158\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000309944\n",
      "\tbias_vis_max: 0.0177602395415\n",
      "\tbias_vis_mean: 0.0140340402722\n",
      "\tbias_vis_min: 0.0089308694005\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.870000004768\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 7.127e+04\n",
      "\treconstruction_error: 8.391e+08\n",
      "\ttotal_seconds_last_epoch: 8.5149230957\n",
      "\ttraining_seconds_this_epoch: 4.82504987717\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.678650 seconds\n",
      "Time this epoch: 4.835950 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tbias_hid_max: -1.99999976158\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000309944\n",
      "\tbias_vis_max: 0.0212481785566\n",
      "\tbias_vis_mean: 0.0168071091175\n",
      "\tbias_vis_min: 0.0106909302995\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.870000004768\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 5.433e+04\n",
      "\treconstruction_error: 8.268e+08\n",
      "\ttotal_seconds_last_epoch: 8.79226112366\n",
      "\ttraining_seconds_this_epoch: 4.8359503746\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.429096 seconds\n",
      "Time this epoch: 4.867749 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tbias_hid_max: -1.99999976158\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000309944\n",
      "\tbias_vis_max: 0.0240286812186\n",
      "\tbias_vis_mean: 0.0190196298063\n",
      "\tbias_vis_min: 0.0120789092034\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.870000004768\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 4.472e+04\n",
      "\treconstruction_error: 8.171e+08\n",
      "\ttotal_seconds_last_epoch: 8.53643417358\n",
      "\ttraining_seconds_this_epoch: 4.86774969101\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.621707 seconds\n",
      "Time this epoch: 4.944764 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tbias_hid_max: -1.99999976158\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000309944\n",
      "\tbias_vis_max: 0.026376331225\n",
      "\tbias_vis_mean: 0.0208889506757\n",
      "\tbias_vis_min: 0.0132625186816\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.870000004768\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 3.842e+04\n",
      "\treconstruction_error: 8.089e+08\n",
      "\ttotal_seconds_last_epoch: 8.76006317139\n",
      "\ttraining_seconds_this_epoch: 4.94476413727\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.715076 seconds\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.417663 seconds\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      " Unsupervised training done! Start Fine-tuing training...\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.00200000009499\n",
      "\tbias_vis: 0.00200000009499\n",
      "\tbias_hid: 0.00200000009499\n",
      "\tsigma_driver: 0.00200000009499\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.427585 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.014676 seconds\n",
      "Monitored channels: \n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 29\n",
      "Compiling accum done. Time elapsed: 0.165511 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.886e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 6.424044 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.886e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 6.42404413223\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.293721 seconds\n",
      "Time this epoch: 6.427010 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.886e+08\n",
      "\ttotal_seconds_last_epoch: 9.86026573181\n",
      "\ttraining_seconds_this_epoch: 6.42701053619\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.937644 seconds\n",
      "Time this epoch: 6.462509 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.886e+08\n",
      "\ttotal_seconds_last_epoch: 10.5063428879\n",
      "\ttraining_seconds_this_epoch: 6.46250963211\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.159083 seconds\n",
      "Time this epoch: 6.465555 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.886e+08\n",
      "\ttotal_seconds_last_epoch: 9.76160430908\n",
      "\ttraining_seconds_this_epoch: 6.46555519104\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.519516 seconds\n",
      "Time this epoch: 6.298715 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.886e+08\n",
      "\ttotal_seconds_last_epoch: 10.1261520386\n",
      "\ttraining_seconds_this_epoch: 6.29871559143\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.180742 seconds\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.202014 seconds\n",
      "-----------------------------------\n",
      " Unsupervised training layer 0, <class 'pylearn2.models.rbm.GaussianBinaryRBM'>\n",
      "-----------------------------------\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.0010000000475\n",
      "\tbias_vis: 0.0010000000475\n",
      "\tbias_hid: 0.0010000000475\n",
      "\tsigma_driver: 0.0010000000475\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.856380 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.028356 seconds\n",
      "Monitored channels: \n",
      "\tbias_hid_max\n",
      "\tbias_hid_mean\n",
      "\tbias_hid_min\n",
      "\tbias_vis_max\n",
      "\tbias_vis_mean\n",
      "\tbias_vis_min\n",
      "\th_max\n",
      "\th_mean\n",
      "\th_min\n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\treconstruction_error\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 91\n",
      "Compiling accum done. Time elapsed: 0.641968 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0\n",
      "\tbias_vis_max: 0.0\n",
      "\tbias_vis_mean: 0.0\n",
      "\tbias_vis_min: 0.0\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.463169187307\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 8.816e+05\n",
      "\treconstruction_error: 9.027e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 4.822436 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00003790855\n",
      "\tbias_vis_max: 0.0132631473243\n",
      "\tbias_vis_mean: 0.00998433865607\n",
      "\tbias_vis_min: 0.00765910837799\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.88038957119\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 1.125e+05\n",
      "\treconstruction_error: 8.612e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 4.82243585587\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.452502 seconds\n",
      "Time this epoch: 4.939261 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00003790855\n",
      "\tbias_vis_max: 0.018435543403\n",
      "\tbias_vis_mean: 0.0138618089259\n",
      "\tbias_vis_min: 0.0105758560821\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.889080047607\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 7.142e+04\n",
      "\treconstruction_error: 8.438e+08\n",
      "\ttotal_seconds_last_epoch: 8.55253410339\n",
      "\ttraining_seconds_this_epoch: 4.93926095963\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.897617 seconds\n",
      "Time this epoch: 4.907315 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00003790855\n",
      "\tbias_vis_max: 0.0220986474305\n",
      "\tbias_vis_mean: 0.0166030544788\n",
      "\tbias_vis_min: 0.0126403160393\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.889999985695\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 5.444e+04\n",
      "\treconstruction_error: 8.315e+08\n",
      "\ttotal_seconds_last_epoch: 9.11342811584\n",
      "\ttraining_seconds_this_epoch: 4.90731477737\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.482263 seconds\n",
      "Time this epoch: 4.910919 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00003790855\n",
      "\tbias_vis_max: 0.0250140726566\n",
      "\tbias_vis_mean: 0.0187876168638\n",
      "\tbias_vis_min: 0.0142827900127\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.889999985695\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 4.482e+04\n",
      "\treconstruction_error: 8.219e+08\n",
      "\ttotal_seconds_last_epoch: 8.67648983002\n",
      "\ttraining_seconds_this_epoch: 4.91091918945\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.223734 seconds\n",
      "Time this epoch: 4.906898 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00003790855\n",
      "\tbias_vis_max: 0.0274788606912\n",
      "\tbias_vis_mean: 0.020634226501\n",
      "\tbias_vis_min: 0.0156736951321\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.889999985695\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 3.851e+04\n",
      "\treconstruction_error: 8.138e+08\n",
      "\ttotal_seconds_last_epoch: 8.40889453888\n",
      "\ttraining_seconds_this_epoch: 4.9068980217\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.201366 seconds\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.223695 seconds\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      " Unsupervised training done! Start Fine-tuing training...\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.00200000009499\n",
      "\tbias_vis: 0.00200000009499\n",
      "\tbias_hid: 0.00200000009499\n",
      "\tsigma_driver: 0.00200000009499\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.604374 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.014013 seconds\n",
      "Monitored channels: \n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 29\n",
      "Compiling accum done. Time elapsed: 0.164589 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.927e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 6.398619 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.927e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 6.39861917496\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.536354 seconds\n",
      "Time this epoch: 6.340200 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.927e+08\n",
      "\ttotal_seconds_last_epoch: 10.0729322433\n",
      "\ttraining_seconds_this_epoch: 6.34020042419\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.168189 seconds\n",
      "Time this epoch: 6.304544 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.927e+08\n",
      "\ttotal_seconds_last_epoch: 9.64299297333\n",
      "\ttraining_seconds_this_epoch: 6.30454397202\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.088635 seconds\n",
      "Time this epoch: 6.301723 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.927e+08\n",
      "\ttotal_seconds_last_epoch: 9.53421401978\n",
      "\ttraining_seconds_this_epoch: 6.30172300339\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.145403 seconds\n",
      "Time this epoch: 6.220378 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.927e+08\n",
      "\ttotal_seconds_last_epoch: 9.5868768692\n",
      "\ttraining_seconds_this_epoch: 6.22037792206\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.322528 seconds\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.224252 seconds\n",
      "-----------------------------------\n",
      " Unsupervised training layer 0, <class 'pylearn2.models.rbm.GaussianBinaryRBM'>\n",
      "-----------------------------------\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.0010000000475\n",
      "\tbias_vis: 0.0010000000475\n",
      "\tbias_hid: 0.0010000000475\n",
      "\tsigma_driver: 0.0010000000475\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.625566 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.024773 seconds\n",
      "Monitored channels: \n",
      "\tbias_hid_max\n",
      "\tbias_hid_mean\n",
      "\tbias_hid_min\n",
      "\tbias_vis_max\n",
      "\tbias_vis_mean\n",
      "\tbias_vis_min\n",
      "\th_max\n",
      "\th_mean\n",
      "\th_min\n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\treconstruction_error\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 91\n",
      "Compiling accum done. Time elapsed: 0.815445 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0\n",
      "\tbias_vis_max: 0.0\n",
      "\tbias_vis_mean: 0.0\n",
      "\tbias_vis_min: 0.0\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.4635014534\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 8.933e+05\n",
      "\treconstruction_error: 9.147e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 4.793279 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000357628\n",
      "\tbias_vis_max: 0.0138330403715\n",
      "\tbias_vis_mean: 0.00997058022767\n",
      "\tbias_vis_min: 0.00535462005064\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.875626266003\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 1.130e+05\n",
      "\treconstruction_error: 8.727e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 4.79327917099\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.303911 seconds\n",
      "Time this epoch: 4.796152 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000357628\n",
      "\tbias_vis_max: 0.0191102940589\n",
      "\tbias_vis_mean: 0.0138490041718\n",
      "\tbias_vis_min: 0.00756522174925\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.888026714325\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 7.173e+04\n",
      "\treconstruction_error: 8.548e+08\n",
      "\ttotal_seconds_last_epoch: 8.37345123291\n",
      "\ttraining_seconds_this_epoch: 4.79615259171\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.882226 seconds\n",
      "Time this epoch: 4.942161 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000357628\n",
      "\tbias_vis_max: 0.0228569153696\n",
      "\tbias_vis_mean: 0.0165898483247\n",
      "\tbias_vis_min: 0.00908305402845\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.888106822968\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 5.467e+04\n",
      "\treconstruction_error: 8.423e+08\n",
      "\ttotal_seconds_last_epoch: 8.95726776123\n",
      "\ttraining_seconds_this_epoch: 4.94216108322\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 4.117634 seconds\n",
      "Time this epoch: 4.874379 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000357628\n",
      "\tbias_vis_max: 0.0258638896048\n",
      "\tbias_vis_mean: 0.0187772139907\n",
      "\tbias_vis_min: 0.0103015294299\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.890012979507\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 4.500e+04\n",
      "\treconstruction_error: 8.323e+08\n",
      "\ttotal_seconds_last_epoch: 9.36028766632\n",
      "\ttraining_seconds_this_epoch: 4.87437868118\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.220616 seconds\n",
      "Time this epoch: 4.817049 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tbias_hid_max: -1.99999928474\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000357628\n",
      "\tbias_vis_max: 0.0283958464861\n",
      "\tbias_vis_mean: 0.0206255149096\n",
      "\tbias_vis_min: 0.0113373724744\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.892000079155\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 3.866e+04\n",
      "\treconstruction_error: 8.240e+08\n",
      "\ttotal_seconds_last_epoch: 8.37574863434\n",
      "\ttraining_seconds_this_epoch: 4.81704902649\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.777394 seconds\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.205091 seconds\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      " Unsupervised training done! Start Fine-tuing training...\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.00200000009499\n",
      "\tbias_vis: 0.00200000009499\n",
      "\tbias_hid: 0.00200000009499\n",
      "\tsigma_driver: 0.00200000009499\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.410036 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.012157 seconds\n",
      "Monitored channels: \n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 29\n",
      "Compiling accum done. Time elapsed: 0.158334 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 9.046e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 6.266891 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 9.046e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 6.26689147949\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.130901 seconds\n",
      "Time this epoch: 6.192829 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 9.046e+08\n",
      "\ttotal_seconds_last_epoch: 9.55838108063\n",
      "\ttraining_seconds_this_epoch: 6.19282960892\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.063804 seconds\n",
      "Time this epoch: 6.161233 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 9.046e+08\n",
      "\ttotal_seconds_last_epoch: 9.39052581787\n",
      "\ttraining_seconds_this_epoch: 6.1612329483\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.103050 seconds\n",
      "Time this epoch: 6.425397 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 9.046e+08\n",
      "\ttotal_seconds_last_epoch: 9.40943527222\n",
      "\ttraining_seconds_this_epoch: 6.42539739609\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.191380 seconds\n",
      "Time this epoch: 6.226812 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 9.046e+08\n",
      "\ttotal_seconds_last_epoch: 9.76096630096\n",
      "\ttraining_seconds_this_epoch: 6.22681188583\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.059166 seconds\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.059064 seconds\n",
      "-----------------------------------\n",
      " Unsupervised training layer 0, <class 'pylearn2.models.rbm.GaussianBinaryRBM'>\n",
      "-----------------------------------\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.0010000000475\n",
      "\tbias_vis: 0.0010000000475\n",
      "\tbias_hid: 0.0010000000475\n",
      "\tsigma_driver: 0.0010000000475\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.638529 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.254226 seconds\n",
      "Monitored channels: \n",
      "\tbias_hid_max\n",
      "\tbias_hid_mean\n",
      "\tbias_hid_min\n",
      "\tbias_vis_max\n",
      "\tbias_vis_mean\n",
      "\tbias_vis_min\n",
      "\th_max\n",
      "\th_mean\n",
      "\th_min\n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\treconstruction_error\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 91\n",
      "Compiling accum done. Time elapsed: 0.617230 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0\n",
      "\tbias_vis_max: 0.0\n",
      "\tbias_vis_mean: 0.0\n",
      "\tbias_vis_min: 0.0\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.468600451946\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 8.701e+05\n",
      "\treconstruction_error: 8.910e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 4.981442 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tbias_hid_max: -1.99999928474\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00002384186\n",
      "\tbias_vis_max: 0.0126114729792\n",
      "\tbias_vis_mean: 0.0100907851011\n",
      "\tbias_vis_min: 0.00729045411572\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.88690662384\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 1.119e+05\n",
      "\treconstruction_error: 8.489e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 4.98144245148\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.349080 seconds\n",
      "Time this epoch: 4.857086 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tbias_hid_max: -1.99999856949\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00002384186\n",
      "\tbias_vis_max: 0.0174676217139\n",
      "\tbias_vis_mean: 0.0140098650008\n",
      "\tbias_vis_min: 0.0101294927299\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.902053356171\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 7.102e+04\n",
      "\treconstruction_error: 8.313e+08\n",
      "\ttotal_seconds_last_epoch: 8.62044429779\n",
      "\ttraining_seconds_this_epoch: 4.85708665848\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 4.028788 seconds\n",
      "Time this epoch: 4.882702 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tbias_hid_max: -1.99999856949\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00002384186\n",
      "\tbias_vis_max: 0.0209140572697\n",
      "\tbias_vis_mean: 0.0167791061103\n",
      "\tbias_vis_min: 0.0120746567845\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.904000043869\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 5.413e+04\n",
      "\treconstruction_error: 8.188e+08\n",
      "\ttotal_seconds_last_epoch: 9.1595697403\n",
      "\ttraining_seconds_this_epoch: 4.88270235062\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.536924 seconds\n",
      "Time this epoch: 4.873048 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tbias_hid_max: -1.99999856949\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00002384186\n",
      "\tbias_vis_max: 0.0236514173448\n",
      "\tbias_vis_mean: 0.0189877841622\n",
      "\tbias_vis_min: 0.013633524999\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.904000043869\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 4.455e+04\n",
      "\treconstruction_error: 8.090e+08\n",
      "\ttotal_seconds_last_epoch: 8.70405769348\n",
      "\ttraining_seconds_this_epoch: 4.87304782867\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.174901 seconds\n",
      "Time this epoch: 4.808456 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tbias_hid_max: -1.99999856949\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00002384186\n",
      "\tbias_vis_max: 0.0259607024491\n",
      "\tbias_vis_mean: 0.0208535529673\n",
      "\tbias_vis_min: 0.0149503247812\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.904000043869\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 3.827e+04\n",
      "\treconstruction_error: 8.007e+08\n",
      "\ttotal_seconds_last_epoch: 8.32807540894\n",
      "\ttraining_seconds_this_epoch: 4.80845594406\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.152323 seconds\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.231970 seconds\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      " Unsupervised training done! Start Fine-tuing training...\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.00200000009499\n",
      "\tbias_vis: 0.00200000009499\n",
      "\tbias_hid: 0.00200000009499\n",
      "\tsigma_driver: 0.00200000009499\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.436266 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.012769 seconds\n",
      "Monitored channels: \n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 29\n",
      "Compiling accum done. Time elapsed: 0.169533 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.809e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 6.216680 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.809e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 6.21668052673\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.135941 seconds\n",
      "Time this epoch: 6.230798 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.809e+08\n",
      "\ttotal_seconds_last_epoch: 9.48668289185\n",
      "\ttraining_seconds_this_epoch: 6.23079776764\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.830582 seconds\n",
      "Time this epoch: 6.286015 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.809e+08\n",
      "\ttotal_seconds_last_epoch: 10.1966266632\n",
      "\ttraining_seconds_this_epoch: 6.28601503372\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.092734 seconds\n",
      "Time this epoch: 6.322417 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.809e+08\n",
      "\ttotal_seconds_last_epoch: 9.5139541626\n",
      "\ttraining_seconds_this_epoch: 6.32241725922\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.104013 seconds\n",
      "Time this epoch: 6.316040 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.809e+08\n",
      "\ttotal_seconds_last_epoch: 9.56553077698\n",
      "\ttraining_seconds_this_epoch: 6.31604003906\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.075703 seconds\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.132891 seconds\n",
      "-----------------------------------\n",
      " Unsupervised training layer 0, <class 'pylearn2.models.rbm.GaussianBinaryRBM'>\n",
      "-----------------------------------\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.0010000000475\n",
      "\tbias_vis: 0.0010000000475\n",
      "\tbias_hid: 0.0010000000475\n",
      "\tsigma_driver: 0.0010000000475\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.846722 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.025934 seconds\n",
      "Monitored channels: \n",
      "\tbias_hid_max\n",
      "\tbias_hid_mean\n",
      "\tbias_hid_min\n",
      "\tbias_vis_max\n",
      "\tbias_vis_mean\n",
      "\tbias_vis_min\n",
      "\th_max\n",
      "\th_mean\n",
      "\th_min\n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\treconstruction_error\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 91\n",
      "Compiling accum done. Time elapsed: 0.605264 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0\n",
      "\tbias_vis_max: 0.0\n",
      "\tbias_vis_mean: 0.0\n",
      "\tbias_vis_min: 0.0\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.468188464642\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 8.742e+05\n",
      "\treconstruction_error: 8.951e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 4.820885 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 150\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000128746\n",
      "\tbias_vis_max: 0.0122674880549\n",
      "\tbias_vis_mean: 0.0101168286055\n",
      "\tbias_vis_min: 0.00687388889492\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.865503907204\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 1.121e+05\n",
      "\treconstruction_error: 8.535e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 4.82088518143\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.342672 seconds\n",
      "Time this epoch: 4.888247 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 300\n",
      "\tExamples seen: 300\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000128746\n",
      "\tbias_vis_max: 0.0169025622308\n",
      "\tbias_vis_mean: 0.0140442959964\n",
      "\tbias_vis_min: 0.00945704616606\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.876080036163\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 7.119e+04\n",
      "\treconstruction_error: 8.361e+08\n",
      "\ttotal_seconds_last_epoch: 8.43779373169\n",
      "\ttraining_seconds_this_epoch: 4.88824701309\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.311794 seconds\n",
      "Time this epoch: 4.889785 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 450\n",
      "\tExamples seen: 450\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000128746\n",
      "\tbias_vis_max: 0.020188767463\n",
      "\tbias_vis_mean: 0.0168199408799\n",
      "\tbias_vis_min: 0.0113310758024\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.880013346672\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 5.426e+04\n",
      "\treconstruction_error: 8.238e+08\n",
      "\ttotal_seconds_last_epoch: 8.47244262695\n",
      "\ttraining_seconds_this_epoch: 4.88978481293\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.415923 seconds\n",
      "Time this epoch: 4.733486 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 600\n",
      "\tExamples seen: 600\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000128746\n",
      "\tbias_vis_max: 0.0228166468441\n",
      "\tbias_vis_mean: 0.019034024328\n",
      "\tbias_vis_min: 0.0128197409213\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.880826711655\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 4.467e+04\n",
      "\treconstruction_error: 8.141e+08\n",
      "\ttotal_seconds_last_epoch: 8.59232139587\n",
      "\ttraining_seconds_this_epoch: 4.73348665237\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.296100 seconds\n",
      "Time this epoch: 4.777828 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 750\n",
      "\tExamples seen: 750\n",
      "\tbias_hid_max: -1.99999988079\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.0000128746\n",
      "\tbias_vis_max: 0.0250391941518\n",
      "\tbias_vis_mean: 0.0209045428783\n",
      "\tbias_vis_min: 0.0140788536519\n",
      "\th_max: 1.0\n",
      "\th_mean: 0.882000029087\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 3.837e+04\n",
      "\treconstruction_error: 8.059e+08\n",
      "\ttotal_seconds_last_epoch: 8.30275535583\n",
      "\ttraining_seconds_this_epoch: 4.77782821655\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.525045 seconds\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.253908 seconds\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      " Unsupervised training done! Start Fine-tuing training...\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.00200000009499\n",
      "\tbias_vis: 0.00200000009499\n",
      "\tbias_hid: 0.00200000009499\n",
      "\tsigma_driver: 0.00200000009499\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.409933 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.012180 seconds\n",
      "Monitored channels: \n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 29\n",
      "Compiling accum done. Time elapsed: 0.172785 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.850e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 80000000 bytes of device memory (out of memory).\nApply node that caused the error: GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Shape_i{1}.0, Shape_i{1}.0)\nInputs types: [CudaNdarrayType(float32, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), ()]\nInputs strides: [(), (), ()]\nInputs values: [<CudaNdarray object at 0x7f4e888d6670>, array(40000), array(500)]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-48aa398ac869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mencoder_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDenseDesignMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#t = copy.copy(np.asarray(train[2]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f7cf6347060a>\u001b[0m in \u001b[0;36mencoder_model\u001b[1;34m(trainset)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;31m#layer_trainers[-1].main_loop()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_layer_trainer_sgd_autoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pitodogo/pylearn2/pylearn2/train.pyc\u001b[0m in \u001b[0;36mmain_loop\u001b[1;34m(self, time_budget)\u001b[0m\n\u001b[0;32m    218\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_seconds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                     ):\n\u001b[1;32m--> 220\u001b[1;33m                         \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mrval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                         raise ValueError(\n",
      "\u001b[1;32m/home/pitodogo/pylearn2/pylearn2/training_algorithms/sgd.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mon_load_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msgd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m             \u001b[1;31m# iterator might return a smaller batch if dataset size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[1;31m# isn't divisible by batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pitodogo/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[0;32m    607\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m                     \u001b[1;31m# For the c linker We don't have access from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pitodogo/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 80000000 bytes of device memory (out of memory).\nApply node that caused the error: GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Shape_i{1}.0, Shape_i{1}.0)\nInputs types: [CudaNdarrayType(float32, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), ()]\nInputs strides: [(), (), ()]\nInputs values: [<CudaNdarray object at 0x7f4e888d6670>, array(40000), array(500)]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "def random_split(data):\n",
    "    train = []\n",
    "    test = np.asarray([])\n",
    "    labels = []\n",
    "    for i in range(len(groups)):\n",
    "        labels = labels + [i]*150\n",
    "        current_set = data[i]\n",
    "        np.random.shuffle(current_set)\n",
    "        if(len(test)==0):\n",
    "#            train = current_set[:150]\n",
    "            test = current_set[150:]\n",
    "        else:\n",
    "#            train = np.vstack([train,current_set[:150]])\n",
    "            test = np.vstack([test,current_set[150:]])\n",
    "        train.append(current_set[:150])\n",
    "        \n",
    "    return train,test,labels\n",
    "\n",
    "train,test,label = random_split(data)\n",
    "\n",
    "encoder_models = []\n",
    "for k,train in enumerate(train):\n",
    "    t = copy.copy(np.asarray(train))\n",
    "    encoder_models.append(encoder_model(DenseDesignMatrix(X=t,y=None)))\n",
    "\n",
    "#t = copy.copy(np.asarray(train[2]))\n",
    "#encoder_models.append(encoder_model(DenseDesignMatrix(X=t,y=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      " Unsupervised training layer 0, <class 'pylearn2.models.rbm.GaussianBinaryRBM'>\n",
      "-----------------------------------\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.0010000000475\n",
      "\tbias_vis: 0.0010000000475\n",
      "\tbias_hid: 0.0010000000475\n",
      "\tsigma_driver: 0.0010000000475\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.275843 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.016108 seconds\n",
      "Monitored channels: \n",
      "\tbias_hid_max\n",
      "\tbias_hid_mean\n",
      "\tbias_hid_min\n",
      "\tbias_vis_max\n",
      "\tbias_vis_mean\n",
      "\tbias_vis_min\n",
      "\th_max\n",
      "\th_mean\n",
      "\th_min\n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\treconstruction_error\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 187\n",
      "Compiling accum done. Time elapsed: 0.368952 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tbias_hid_max: -2.00000023842\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000023842\n",
      "\tbias_vis_max: 0.0\n",
      "\tbias_vis_mean: 0.0\n",
      "\tbias_vis_min: 0.0\n",
      "\th_max: 1.00000011921\n",
      "\th_mean: 0.463871687651\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 8.815e+05\n",
      "\treconstruction_error: 9.027e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 1.548846 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 15\n",
      "\tExamples seen: 150\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000548363\n",
      "\tbias_vis_max: 0.00354578718543\n",
      "\tbias_vis_mean: 0.00256508029997\n",
      "\tbias_vis_min: 0.00124146684539\n",
      "\th_max: 1.00000011921\n",
      "\th_mean: 0.829789280891\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 4.159e+05\n",
      "\treconstruction_error: 8.928e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 1.54884588718\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.290159 seconds\n",
      "Time this epoch: 1.524544 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 30\n",
      "\tExamples seen: 300\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000548363\n",
      "\tbias_vis_max: 0.00565067445859\n",
      "\tbias_vis_mean: 0.0040897866711\n",
      "\tbias_vis_min: 0.00195226678625\n",
      "\th_max: 1.00000011921\n",
      "\th_mean: 0.856256246567\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 2.952e+05\n",
      "\treconstruction_error: 8.859e+08\n",
      "\ttotal_seconds_last_epoch: 5.43394088745\n",
      "\ttraining_seconds_this_epoch: 1.52454388142\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.351023 seconds\n",
      "Time this epoch: 1.516653 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 45\n",
      "\tExamples seen: 450\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000548363\n",
      "\tbias_vis_max: 0.00723926303908\n",
      "\tbias_vis_mean: 0.00524270394817\n",
      "\tbias_vis_min: 0.00249481084757\n",
      "\th_max: 1.00000011921\n",
      "\th_mean: 0.868253290653\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 2.356e+05\n",
      "\treconstruction_error: 8.806e+08\n",
      "\ttotal_seconds_last_epoch: 5.42982244492\n",
      "\ttraining_seconds_this_epoch: 1.51665318012\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.811309 seconds\n",
      "Time this epoch: 1.521050 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 60\n",
      "\tExamples seen: 600\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000548363\n",
      "\tbias_vis_max: 0.00854012090713\n",
      "\tbias_vis_mean: 0.00619076797739\n",
      "\tbias_vis_min: 0.00294796191156\n",
      "\th_max: 1.00000011921\n",
      "\th_mean: 0.875679969788\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 1.990e+05\n",
      "\treconstruction_error: 8.763e+08\n",
      "\ttotal_seconds_last_epoch: 5.8820514679\n",
      "\ttraining_seconds_this_epoch: 1.52104985714\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.282799 seconds\n",
      "Time this epoch: 1.537500 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 75\n",
      "\tExamples seen: 750\n",
      "\tbias_hid_max: -2.0\n",
      "\tbias_hid_mean: -2.00000023842\n",
      "\tbias_hid_min: -2.00000548363\n",
      "\tbias_vis_max: 0.00965928100049\n",
      "\tbias_vis_mean: 0.00700615858659\n",
      "\tbias_vis_min: 0.0033382254187\n",
      "\th_max: 1.00000011921\n",
      "\th_mean: 0.879186630249\n",
      "\th_min: 0.0\n",
      "\tlearning_rate: 0.0010000000475\n",
      "\tobjective: 1.738e+05\n",
      "\treconstruction_error: 8.725e+08\n",
      "\ttotal_seconds_last_epoch: 5.3629193306\n",
      "\ttraining_seconds_this_epoch: 1.53749990463\n",
      "monitoring channel is objective\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.268851 seconds\n",
      "Saving to grbm.pkl...\n",
      "Saving to grbm.pkl done. Time elapsed: 3.255303 seconds\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      " Unsupervised training done! Start Fine-tuing training...\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Parameter and initial learning rate summary:\n",
      "\tW: 0.00200000009499\n",
      "\tbias_vis: 0.00200000009499\n",
      "\tbias_hid: 0.00200000009499\n",
      "\tsigma_driver: 0.00200000009499\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.213300 seconds\n",
      "compiling begin_record_entry...\n",
      "compiling begin_record_entry done. Time elapsed: 0.006814 seconds\n",
      "Monitored channels: \n",
      "\tlearning_rate\n",
      "\tobjective\n",
      "\ttotal_seconds_last_epoch\n",
      "\ttraining_seconds_this_epoch\n",
      "Compiling accum...\n",
      "graph size: 54\n",
      "Compiling accum done. Time elapsed: 0.100708 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 0\n",
      "\tBatches seen: 0\n",
      "\tExamples seen: 0\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.933e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 0.0\n",
      "Time this epoch: 3.117002 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 1\n",
      "\tBatches seen: 30\n",
      "\tExamples seen: 150\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.926e+08\n",
      "\ttotal_seconds_last_epoch: 0.0\n",
      "\ttraining_seconds_this_epoch: 3.11700224876\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 2.987845 seconds\n",
      "Time this epoch: 3.109939 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 2\n",
      "\tBatches seen: 60\n",
      "\tExamples seen: 300\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.926e+08\n",
      "\ttotal_seconds_last_epoch: 6.24195194244\n",
      "\ttraining_seconds_this_epoch: 3.10993909836\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 4.111245 seconds\n",
      "Time this epoch: 3.162731 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 3\n",
      "\tBatches seen: 90\n",
      "\tExamples seen: 450\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.926e+08\n",
      "\ttotal_seconds_last_epoch: 7.3600320816\n",
      "\ttraining_seconds_this_epoch: 3.16273093224\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.358868 seconds\n",
      "Time this epoch: 3.116053 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 4\n",
      "\tBatches seen: 120\n",
      "\tExamples seen: 600\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.926e+08\n",
      "\ttotal_seconds_last_epoch: 6.65798187256\n",
      "\ttraining_seconds_this_epoch: 3.1160531044\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 2.981502 seconds\n",
      "Time this epoch: 3.121671 seconds\n",
      "Monitoring step:\n",
      "\tEpochs seen: 5\n",
      "\tBatches seen: 150\n",
      "\tExamples seen: 750\n",
      "\tlearning_rate: 0.00200000009499\n",
      "\tobjective: 8.926e+08\n",
      "\ttotal_seconds_last_epoch: 6.23379421234\n",
      "\ttraining_seconds_this_epoch: 3.1216711998\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 3.001387 seconds\n",
      "Saving to my_model.pkl...\n",
      "Saving to my_model.pkl done. Time elapsed: 2.978199 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = copy.copy(np.asarray(train[3]))\n",
    "encoder_models.append(encoder_model(DenseDesignMatrix(X=t,y=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pylearn2.models.DRM.DeepEncoder at 0x7f865fcf2fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9691bb39fa15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredicted_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mtotal_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mcorrect_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_label\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_label' is not defined"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "X = encoder_models[0].get_input_space().make_theano_batch(batch_size=1000)\n",
    "output_pool = []\n",
    "\n",
    "for encoder in encoder_models:\n",
    "    X_hat = encoder.reconstruct(X)\n",
    "    loss_data = ((X - X_hat)**2).sum(axis=1)\n",
    "    output_pool.append(loss_data)\n",
    "\n",
    "f = theano.function([X],output_pool)\n",
    "\n",
    "\n",
    "def find_predictions(data):\n",
    "    reconstruct_result = f(data)\n",
    "    predictions = []\n",
    "    votes_bucket = [0 for i in range(len(reconstruct_result))]\n",
    "    for i in range(len(reconstruct_result[0])):\n",
    "        reconstruct_err_values = []\n",
    "        for j in range(len(reconstruct_result)):\n",
    "            reconstruct_err_values.append(reconstruct_result[j][i])\n",
    "        minimal_reconstruction = min(reconstruct_err_values)\n",
    "        prediction = reconstruct_err_values.index(minimal_reconstruction) + 1\n",
    "        predictions.append(prediction)\n",
    "        votes_bucket[prediction-1] += 1\n",
    "    \n",
    "    maximal_predicted = max(votes_bucket)\n",
    "    predicted_class = votes_bucket.index(maximal_predicted) + 1\n",
    "    return predicted_class,predictions\n",
    "\n",
    "total_number = float(len(test_label))\n",
    "correct_count = 0\n",
    "for k,true_label in enumerate(test_label):\n",
    "    pred,_ = find_predictions(copy.copy(test_data[k][0]))\n",
    "    if(pred==true_label):\n",
    "        correct_count += 1\n",
    "print(correct_count/total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "ff = open(\"trial_train.pkl\",\"wb\")\n",
    "cPickle.dump(encoder_models,ff)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "('Error allocating 80000000 bytes of device memory (out of memory).', <function CudaNdarray_unpickler at 0x7f94a6756320>, (array([[-0.01937678,  0.01412687,  0.00724369, ..., -0.01132945,\n         0.01676371,  0.07814937],\n       [ 0.0021261 ,  0.01960999,  0.02260183, ..., -0.01281641,\n        -0.03500316,  0.00452814],\n       [-0.03906006, -0.01323096,  0.01107634, ...,  0.01785509,\n        -0.03305104,  0.06571223],\n       ..., \n       [ 0.03632317,  0.03930932,  0.05246469, ..., -0.0083575 ,\n        -0.0417932 ,  0.08342919],\n       [ 0.03506872,  0.06747298,  0.0748592 , ...,  0.02429776,\n        -0.01334724,  0.11005408],\n       [ 0.0028928 ,  0.0510247 ,  0.12638801, ..., -0.0455821 ,\n        -0.03785853,  0.07617415]], dtype=float32),))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4552dbe58ef1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trial_train.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mencoder_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/pitodogo/anaconda/lib/python2.7/site-packages/theano/sandbox/cuda/type.pyc\u001b[0m in \u001b[0;36mCudaNdarray_unpickler\u001b[1;34m(npa)\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnpa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCudaNdarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cuda not found. Cannot unpickle CudaNdarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ('Error allocating 80000000 bytes of device memory (out of memory).', <function CudaNdarray_unpickler at 0x7f94a6756320>, (array([[-0.01937678,  0.01412687,  0.00724369, ..., -0.01132945,\n         0.01676371,  0.07814937],\n       [ 0.0021261 ,  0.01960999,  0.02260183, ..., -0.01281641,\n        -0.03500316,  0.00452814],\n       [-0.03906006, -0.01323096,  0.01107634, ...,  0.01785509,\n        -0.03305104,  0.06571223],\n       ..., \n       [ 0.03632317,  0.03930932,  0.05246469, ..., -0.0083575 ,\n        -0.0417932 ,  0.08342919],\n       [ 0.03506872,  0.06747298,  0.0748592 , ...,  0.02429776,\n        -0.01334724,  0.11005408],\n       [ 0.0028928 ,  0.0510247 ,  0.12638801, ..., -0.0455821 ,\n        -0.03785853,  0.07617415]], dtype=float32),))"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "ff = open(\"trial_train.pkl\",\"rb\")\n",
    "encoder_models = cPickle.load(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d8e8fca2dc0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
